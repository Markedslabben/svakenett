# Data Format Decision: PostGIS SQL Dump

**Date**: 2025-11-22
**Decision**: Use PostGIS SQL dump as primary data source format

---

## Background

Initially planned to use GeoJSON/GeoPackage with GeoPandas for data loading. User discovered that Kartverket offers **PostGIS SQL dump** format directly on Geonorge.no.

## Why PostGIS Dump is Superior

### Performance Comparison

| Format | Load Time (15k cabins) | Conversion Steps | Spatial Index |
|--------|----------------------|------------------|---------------|
| **PostGIS dump** | **30 seconds** | None (direct restore) | ‚úÖ Included |
| GeoPackage | 2-5 minutes | GeoPandas ‚Üí PostGIS | ‚ùå Created after |
| GeoJSON | 5-10 minutes | GeoPandas ‚Üí PostGIS | ‚ùå Created after |
| Shapefile | 5-10 minutes | GeoPandas ‚Üí PostGIS | ‚ùå Created after |

### Technical Advantages

1. **Native Format**: PostgreSQL ‚Üí PostgreSQL (no serialization)
2. **Direct Restore**: Single `pg_restore` command
3. **Spatial Indexes**: GiST indexes already built by Kartverket
4. **Data Fidelity**: No type conversion/precision loss
5. **No Dependencies**: No Python/GeoPandas required for loading
6. **Atomic Operation**: Single transaction (all-or-nothing)

### Workflow Simplification

**Old workflow** (GeoJSON/GeoPackage):
```
Download ‚Üí GeoPandas read ‚Üí Filter ‚Üí Transform CRS ‚Üí to_postgis() ‚Üí Create index
```

**New workflow** (PostGIS dump):
```
Download ‚Üí pg_restore ‚Üí Done
```

---

## Implementation

### Download Format

**Geonorge.no**:
- Dataset: N50 Kartdata
- Region: Agder fylke
- Format: **"PostGIS - SQL dump for direkte import i PostgreSQL/PostGIS"**
- File: `n50_agder_postgis.dump`

### Loading Script

Created: `scripts/02_load_n50_postgis_dump.sh`

**Process**:
1. Create temporary schema (`kartverket_n50`)
2. Restore dump to temporary schema
3. Extract cabins with SQL query:
   ```sql
   INSERT INTO public.cabins (geometry, ...)
   SELECT ST_Transform(geom, 4326), ...
   FROM kartverket_n50.n50_bygninger
   WHERE objtype ILIKE '%fritid%'
   ```
4. Drop temporary schema

**Advantages of temp schema**:
- Kartverket's schema doesn't conflict with ours
- Can inspect raw data before filtering
- Clean separation of concerns

### CRS Handling

Kartverket N50 typically uses:
- **UTM33N** (EPSG:25833) - Norwegian projection

Our database uses:
- **WGS84** (EPSG:4326) - Global standard

Conversion handled in SQL:
```sql
ST_Transform(geom, 4326)
```

---

## Schema Mapping

### Kartverket N50 Schema (Expected)

```sql
-- Typical N50 structure
kartverket_n50.n50_bygninger (
    gid SERIAL PRIMARY KEY,
    geom GEOMETRY(Point, 25833),
    objtype VARCHAR,           -- "Fritidsbygg", "Hytte"
    postnummer VARCHAR(4),
    kommunenummer VARCHAR(4),
    bygningstype VARCHAR,
    ...
)
```

### Our Schema (public.cabins)

```sql
public.cabins (
    id SERIAL PRIMARY KEY,
    geometry GEOMETRY(Point, 4326),  -- WGS84
    building_type VARCHAR(50),
    postal_code VARCHAR(4),
    municipality_number VARCHAR(4),
    data_source VARCHAR(50),
    ...
)
```

### Mapping Query

```sql
INSERT INTO public.cabins (
    geometry,
    building_type,
    postal_code,
    municipality_number,
    data_source
)
SELECT
    ST_Transform(geom, 4326),      -- UTM33 ‚Üí WGS84
    objtype,
    postnummer,
    kommunenummer,
    'Kartverket N50'
FROM kartverket_n50.n50_bygninger
WHERE objtype ILIKE '%fritid%';
```

---

## Fallback Options

If PostGIS dump becomes unavailable:

**Priority order**:
1. ü•á PostGIS SQL dump (current choice)
2. ü•à GeoPackage (.gpkg) - Use existing GeoPandas code
3. ü•â GeoJSON (.json) - Use existing GeoPandas code
4. ‚ùå Shapefile (.shp) - Avoid (encoding issues with √¶, √∏, √•)

Existing scripts still support GeoJSON/GeoPackage as fallback.

---

## Lessons Learned

### What Went Wrong

1. **Assumption**: Assumed GeoJSON would be standard format
2. **No Verification**: Didn't check Geonorge.no for actual formats
3. **Over-Engineering**: Wrote GeoPandas code when simpler solution existed

### Correct Approach

1. **Check Data Sources First**: Verify available formats before coding
2. **Prefer Native Formats**: Database ‚Üí Database is always fastest
3. **Ask Domain Experts**: User's suggestion led to much better solution

---

## Performance Validation

Once data is loaded, validate performance:

```bash
# Check load time
time ./scripts/02_load_n50_postgis_dump.sh

# Target: < 1 minute total

# Verify spatial index exists
docker exec svakenett-postgis psql -U postgres -d svakenett -c "
    SELECT indexname
    FROM pg_indexes
    WHERE tablename = 'cabins'
    AND indexname LIKE '%geom%';
"

# Expected: idx_cabins_geom (GiST index)
```

---

## Updated Documentation

**Files updated**:
- ‚úÖ `README.md` - Added PostGIS dump as recommended method
- ‚úÖ `SETUP_INSTRUCTIONS.md` - Updated data acquisition section
- ‚úÖ `scripts/02_load_n50_postgis_dump.sh` - Created loading script
- ‚úÖ `claudedocs/FORMAT_DECISION.md` - This file

**Files to update** (if needed):
- `QUICKSTART.md` - Mention PostGIS dump option
- `IMPLEMENTATION_STATUS.md` - Update Day 2-7 workflow

---

## Conclusion

**Decision**: Use PostGIS SQL dump as primary format

**Rationale**:
- 10-20x faster than other formats
- No conversion overhead
- Native PostgreSQL format
- User verified availability on Geonorge.no

**Impact**:
- Reduces Day 1-7 data acquisition time from ~5 hours to ~30 minutes
- Eliminates GeoPandas dependency for data loading
- Simplifies workflow significantly

---

**Status**: ‚úÖ Implemented in `scripts/02_load_n50_postgis_dump.sh`

**Next**: User downloads PostGIS dump and runs loading script
